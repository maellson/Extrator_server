import json
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
import os
import pytesseract
from pdf2image import convert_from_path
import fitz  # PyMuPDF para p√°ginas vetoriais
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()

# Configura√ß√£o do OCR
# ajuste o caminho se necess√°rio
pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/bin/tesseract'

# Caminhos
pdf_path = "arquivos_pdf/documento.pdf"
images_dir = "imagens_paginas"
texts_dir = "textos_paginas"

os.makedirs(images_dir, exist_ok=True)
os.makedirs(texts_dir, exist_ok=True)


def extrair_texto_via_ocr(pdf_path):
    paginas = convert_from_path(pdf_path, dpi=300)
    textos_paginas = []

    for num, pagina in enumerate(paginas, start=1):
        img_path = os.path.join(images_dir, f'pagina_{num}.png')
        pagina.save(img_path, 'PNG')

        texto = pytesseract.image_to_string(img_path, lang='por')
        textos_paginas.append((num, texto))

        with open(os.path.join(texts_dir, f'pagina_{num}.txt'), 'w', encoding='utf-8') as f:
            f.write(texto)

        print(f'Texto extra√≠do da p√°gina {num}.')

    return textos_paginas


def extrair_texto_vetorial(pdf_path):
    doc = fitz.open(pdf_path)
    textos_paginas = []

    for num, page in enumerate(doc, start=1):
        texto = page.get_text()
        if texto.strip():
            textos_paginas.append((num, texto))
            with open(os.path.join(texts_dir, f'vetorial_pagina_{num}.txt'), 'w', encoding='utf-8') as f:
                f.write(texto)
            print(f'Texto vetorial extra√≠do da p√°gina {num}.')

    return textos_paginas

# Combina OCR e vetorial, evita duplica√ß√£o de p√°gina


def extrair_texto_completo(pdf_path):
    texto_ocr = dict(extrair_texto_via_ocr(pdf_path))
    texto_vetorial = dict(extrair_texto_vetorial(pdf_path))

    todas_paginas = {**texto_ocr, **texto_vetorial}
    paginas_texto = sorted(todas_paginas.items())
    return paginas_texto

# Construir vector store FAISS


def criar_vector_store(paginas_texto):
    documentos = []
    for num, texto in paginas_texto:
        documentos.append(f"P√°gina {num}:\n{texto}")

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000, chunk_overlap=100)
    chunks = splitter.create_documents(documentos)

    embeddings = OpenAIEmbeddings()
    vector_store = FAISS.from_documents(chunks, embeddings)

    vector_store = FAISS.load_local(
        "faiss_index", embeddings, allow_dangerous_deserialization=True)
    print('√çndice vetorial salvo localmente.')

# Consultar com LangChain e OpenAI


def consultar_vector_store(pergunta):
    embeddings = OpenAIEmbeddings()
    vector_store = FAISS.load_local(
        "faiss_index", embeddings, allow_dangerous_deserialization=True)
    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model="gpt-4o-mini", temperature=0),
        retriever=vector_store.as_retriever(
            search_type="similarity", search_kwargs={"k": 3}),
        return_source_documents=True
    )

    resposta = qa_chain({"query": pergunta})
    return resposta


# --------------------------------------


def classificar_documento(paginas_texto):
    conteudo = "\n\n".join(
        [f"P√°gina {num}:\n{texto}" for num, texto in paginas_texto])

    prompt_template = PromptTemplate.from_template("""
Voc√™ est√° analisando um documento dividido por p√°ginas, onde cada p√°gina come√ßa com 'P√°gina X:'.
Classifique as p√°ginas de acordo com o conte√∫do apresentado. Os tipos de conte√∫do que devem ser detectados s√£o:
- email
- boleto
- nota_fiscal

Considere:
- 'email' cont√©m sauda√ß√µes, mensagens, assinaturas, ou linguagem de comunica√ß√£o.
- 'boleto' cont√©m c√≥digo de barras, vencimento, valor, cedente ou banco.
- 'nota_fiscal' cont√©m CNPJ, descri√ß√£o de produtos/servi√ßos, impostos, natureza da opera√ß√£o.

Responda apenas com um JSON, nesse formato:
{{
  "email": [1, 2],
  "boleto": [3],
  "nota_fiscal": [4, 5]
}}

Aqui est√° o conte√∫do do documento:

{conteudo}
""")

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    chain = LLMChain(llm=llm, prompt=prompt_template)
    resposta = chain.run(conteudo=conteudo)

    try:
        return json.loads(resposta)
    except Exception:
        print("‚ö†Ô∏è Erro ao interpretar resposta do LLM como JSON:")
        print(resposta)
        return {"erro": "Formato inesperado", "resposta_bruta": resposta}


# Execu√ß√£o principal
if __name__ == "__main__":
    print("üìÑ Extraindo texto das p√°ginas...")
    paginas_texto = extrair_texto_completo(pdf_path)

    print("üß† Criando e salvando embeddings vetoriais...")
    criar_vector_store(paginas_texto)

    print("ü§ñ Classificando conte√∫do...")
    classificacao = classificar_documento(paginas_texto)
    print(json.dumps(classificacao, indent=2))

    print("ü§ñ Consultando documento com agente RAG...")
    pergunta = ("Voc√™ est√° analisando um documento PDF que foi dividido por p√°ginas. "
                "Cada p√°gina come√ßa com o texto 'P√°gina X:'. "
                "Seu objetivo √© identificar em qual ou quais p√°ginas aparece uma nota fiscal. "
                "Responda com o seguinte formato: 'nota_fiscal: [X]' ou 'nota_fiscal: [X-Y]'.")

    resultado = consultar_vector_store(pergunta)

    print("\nüîé Resposta do Agente IA:")
    print(resultado["result"])

    print("\nüìë Documentos fontes usados na resposta:")
    for doc in resultado["source_documents"]:
        print(doc.page_content[:200], "...\n")
